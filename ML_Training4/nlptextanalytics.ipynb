{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural Language Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### using PYTHON"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='NLP01.jpg'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What are we going to touch upon\n",
    "\n",
    "### 1. CountVectorizer\n",
    "### 2. Ngrams\n",
    "### 3.Stop-Words\n",
    "### 4.DF-Document frequency\n",
    "### 5.Stemming\n",
    "### 6.Lemmatization\n",
    "### 7.TF-iDF\n",
    "### 8.Sentimental Analysis\n",
    "### 9.Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'textblob'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-b693ee7a0da7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear_model\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtextblob\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mTextBlob\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mWord\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msnowball\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSnowballStemmer\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'matplotlib'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'inline'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'textblob'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from textblob import TextBlob, Word\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='getready.jpg'>\n",
    "\n",
    "### Use Yelp dataset\n",
    "<img src='yelp.jpg'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              business_id        date               review_id  stars  \\\n",
      "0  9yKzy9PApeiPPOUJEtnvkg  2011-01-26  fWKvX83p0-ka4JS3dc6E5A      5   \n",
      "1  ZRJwVLyzEJq1VAihDhYiow  2011-07-27  IjZ33sJrzXqU-0X6U8NwyA      5   \n",
      "3  _1QQZuf4zZOyFCvXc0o6Vg  2010-05-27  G-WvGaISbqqaMHlNnByodA      5   \n",
      "4  6ozycU1RpktNG2-1BroVtw  2012-01-05  1uJFq2r5QfJG_6ExMRCaGw      5   \n",
      "6  zp713qNhx8d9KCJJnrw1xA  2010-02-12  riFQ3vxNpP4rWLk_CSri2A      5   \n",
      "\n",
      "                                                text    type  \\\n",
      "0  My wife took me here on my birthday for breakf...  review   \n",
      "1  I have no idea why some people give bad review...  review   \n",
      "3  Rosie, Dakota, and I LOVE Chaparral Dog Park!!...  review   \n",
      "4  General Manager Scott Petello is a good egg!!!...  review   \n",
      "6  Drop what you're doing and drive here. After I...  review   \n",
      "\n",
      "                  user_id  cool  useful  funny  \n",
      "0  rLtl8ZkDX5vH5nAx9C3q5Q     2       5      0  \n",
      "1  0a2KyEL0d3Yb1V6aivbIuQ     0       0      0  \n",
      "3  uZetl9T0NcROGOyFfughhg     1       2      0  \n",
      "4  vYmM4KTsC8ZfQBg-j5MWkw     0       0      0  \n",
      "6  wFweIWhv2fREZV_dYkz_1g     7       7      4  \n",
      "------print X[0]--------\n",
      "My wife took me here on my birthday for breakfast and it was excellent.  The weather was perfect which made sitting outside overlooking their grounds an absolute pleasure.  Our waitress was excellent and our food arrived quickly on the semi-busy Saturday morning.  It looked like the place fills up pretty quickly so the earlier you get here the better.\n",
      "\n",
      "Do yourself a favor and get their Bloody Mary.  It was phenomenal and simply the best I've ever had.  I'm pretty sure they only use ingredients from their garden and blend them fresh when you order it.  It was amazing.\n",
      "\n",
      "While EVERYTHING on the menu looks excellent, I had the white truffle scrambled eggs vegetable skillet and it was tasty and delicious.  It came with 2 pieces of their griddled bread with was amazing and it absolutely made the meal complete.  It was the best \"toast\" I've ever had.\n",
      "\n",
      "Anyway, I can't wait to go back!\n",
      "------print y[0]--------\n",
      "5\n",
      "------print length of X_train--------\n",
      "3064\n"
     ]
    }
   ],
   "source": [
    "# read yelp.csv into a DataFrame\n",
    "url = 'https://raw.githubusercontent.com/justmarkham/DAT8/master/data/yelp.csv'\n",
    "yelp = pd.read_csv(url)\n",
    "\n",
    "# create a new DataFrame that only contains the 5-star and 1-star reviews\n",
    "yelp_best_worst = yelp[(yelp.stars==5) | (yelp.stars==1)]\n",
    "print(yelp_best_worst.head())\n",
    "print(\"------print X[0]--------\")\n",
    "# define X and y\n",
    "X = yelp_best_worst.text\n",
    "print(X[0])\n",
    "print(\"------print y[0]--------\")\n",
    "y = yelp_best_worst.stars\n",
    "print(y[0])\n",
    "print(\"------print length of X_train--------\")\n",
    "# split the new DataFrame into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "print(len(X_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='countvectorizer.jpg'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='BagOfWords.jpg'>\n",
    "Bag of Words (BoW) is an algorithm that counts how many times a word appears in a document. Those word counts allow us to compare documents and gauge their similarities for applications like search, document classification and topic modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My wife took me here on my birthday for breakfast and it was excellent.  The weather was perfect which made sitting outside overlooking their grounds an absolute pleasure.  Our waitress was excellent and our food arrived quickly on the semi-busy Saturday morning.  It looked like the place fills up pretty quickly so the earlier you get here the better.\n",
      "\n",
      "Do yourself a favor and get their Bloody Mary.  It was phenomenal and simply the best I've ever had.  I'm pretty sure they only use ingredients from their garden and blend them fresh when you order it.  It was amazing.\n",
      "\n",
      "While EVERYTHING on the menu looks excellent, I had the white truffle scrambled eggs vegetable skillet and it was tasty and delicious.  It came with 2 pieces of their griddled bread with was amazing and it absolutely made the meal complete.  It was the best \"toast\" I've ever had.\n",
      "\n",
      "Anyway, I can't wait to go back!   (0, 13745)\t1\n",
      "  (0, 4837)\t1\n",
      "  (0, 16394)\t1\n",
      "  (0, 7149)\t1\n",
      "  (0, 3999)\t1\n",
      "  (0, 2069)\t1\n",
      "  (0, 14721)\t1\n",
      "  (0, 12622)\t1\n",
      "  (0, 5882)\t1\n",
      "  (0, 6154)\t1\n",
      "  (0, 12038)\t1\n",
      "  (0, 15281)\t1\n",
      "  (0, 7345)\t1\n",
      "  (0, 1902)\t1\n",
      "  (0, 7023)\t1\n",
      "  (0, 15067)\t1\n",
      "  (0, 12808)\t1\n",
      "  (0, 2398)\t1\n",
      "  (0, 13462)\t1\n",
      "  (0, 9301)\t2\n",
      "  (0, 3213)\t1\n",
      "  (0, 15683)\t1\n",
      "  (0, 6028)\t1\n",
      "  (0, 1528)\t1\n",
      "  (0, 805)\t4\n",
      "  :\t:\n",
      "  (0, 1003)\t1\n",
      "  (0, 2286)\t2\n",
      "  (0, 1018)\t1\n",
      "  (0, 15032)\t2\n",
      "  (0, 3679)\t1\n",
      "  (0, 10286)\t2\n",
      "  (0, 14838)\t1\n",
      "  (0, 2789)\t1\n",
      "  (0, 12514)\t2\n",
      "  (0, 15834)\t1\n",
      "  (0, 16195)\t1\n",
      "  (0, 10413)\t2\n",
      "  (0, 15136)\t1\n",
      "  (0, 4809)\t1\n",
      "  (0, 136)\t1\n",
      "  (0, 11186)\t1\n",
      "  (0, 15093)\t1\n",
      "  (0, 9578)\t1\n",
      "  (0, 4631)\t1\n",
      "  (0, 16612)\t2\n",
      "  (0, 10180)\t1\n",
      "  (0, 10069)\t1\n",
      "  (0, 12465)\t1\n",
      "  (0, 10362)\t2\n",
      "  (0, 5773)\t1\n"
     ]
    }
   ],
   "source": [
    "# use CountVectorizer to create document-term matrices from X_train and X_test\n",
    "vect = CountVectorizer()\n",
    "X_train_dtm = vect.fit_transform(X_train)\n",
    "\n",
    "X_test_dtm = vect.transform(X_test)\n",
    "print(X_train[0], X_train_dtm[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3064, 16825)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rows are documents, columns are terms (aka \"tokens\" or \"features\")\n",
    "X_train_dtm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['yyyyy', 'z11', 'za', 'zabba', 'zach', 'zam', 'zanella', 'zankou', 'zappos', 'zatsiki', 'zen', 'zero', 'zest', 'zexperience', 'zha', 'zhou', 'zia', 'zihuatenejo', 'zilch', 'zin', 'zinburger', 'zinburgergeist', 'zinc', 'zinfandel', 'zing', 'zip', 'zipcar', 'zipper', 'zippers', 'zipps', 'ziti', 'zoe', 'zombi', 'zombies', 'zone', 'zones', 'zoning', 'zoo', 'zoyo', 'zucca', 'zucchini', 'zuchinni', 'zumba', 'zupa', 'zuzu', 'zwiebel', 'zzed', 'éclairs', 'école', 'ém']\n"
     ]
    }
   ],
   "source": [
    "# last 50 features\n",
    "print(vect.get_feature_names()[-50:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show vectorizer options\n",
    "vect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My wife took me here on my birthday for breakfast and it was excellent.  The weather was perfect which made sitting outside overlooking their grounds an absolute pleasure.  Our waitress was excellent and our food arrived quickly on the semi-busy Saturday morning.  It looked like the place fills up pretty quickly so the earlier you get here the better.\n",
      "\n",
      "Do yourself a favor and get their Bloody Mary.  It was phenomenal and simply the best I've ever had.  I'm pretty sure they only use ingredients from their garden and blend them fresh when you order it.  It was amazing.\n",
      "\n",
      "While EVERYTHING on the menu looks excellent, I had the white truffle scrambled eggs vegetable skillet and it was tasty and delicious.  It came with 2 pieces of their griddled bread with was amazing and it absolutely made the meal complete.  It was the best \"toast\" I've ever had.\n",
      "\n",
      "Anyway, I can't wait to go back!   (0, 18233)\t1\n",
      "  (0, 10889)\t1\n",
      "  (0, 20503)\t1\n",
      "  (0, 12846)\t1\n",
      "  (0, 10175)\t1\n",
      "  (0, 8532)\t1\n",
      "  (0, 19097)\t1\n",
      "  (0, 17282)\t1\n",
      "  (0, 11801)\t1\n",
      "  (0, 12035)\t1\n",
      "  (0, 16775)\t1\n",
      "  (0, 19563)\t1\n",
      "  (0, 12998)\t1\n",
      "  (0, 8394)\t1\n",
      "  (0, 12743)\t1\n",
      "  (0, 19378)\t1\n",
      "  (0, 17425)\t1\n",
      "  (0, 8799)\t1\n",
      "  (0, 17978)\t1\n",
      "  (0, 14518)\t2\n",
      "  (0, 9469)\t1\n",
      "  (0, 6576)\t1\n",
      "  (0, 11932)\t1\n",
      "  (0, 8092)\t1\n",
      "  (0, 7507)\t4\n",
      "  :\t:\n",
      "  (0, 7671)\t1\n",
      "  (0, 8704)\t2\n",
      "  (0, 7682)\t1\n",
      "  (0, 19346)\t2\n",
      "  (0, 9900)\t1\n",
      "  (0, 15276)\t2\n",
      "  (0, 19188)\t1\n",
      "  (0, 9111)\t1\n",
      "  (0, 17210)\t2\n",
      "  (0, 20039)\t1\n",
      "  (0, 20329)\t1\n",
      "  (0, 15383)\t2\n",
      "  (0, 19445)\t1\n",
      "  (0, 10863)\t1\n",
      "  (0, 138)\t1\n",
      "  (0, 16020)\t1\n",
      "  (0, 6193)\t1\n",
      "  (0, 14737)\t1\n",
      "  (0, 10716)\t1\n",
      "  (0, 20695)\t2\n",
      "  (0, 15195)\t1\n",
      "  (0, 4360)\t1\n",
      "  (0, 17176)\t1\n",
      "  (0, 15338)\t2\n",
      "  (0, 2376)\t1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3064, 20838)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# don't convert to lowercase\n",
    "vect = CountVectorizer(lowercase=False)\n",
    "X_train_dtm = vect.fit_transform(X_train)\n",
    "print(X_train[0], X_train_dtm[0])\n",
    "X_train_dtm.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An n-gram is a contiguous sequence of n words, for example, in the sentence \"dog that barks does not bite\", the n-grams are:\n",
    "1. unigrams (n=1): dog, that, barks, does, not, bite\n",
    "2. bigrams (n=2): dog that, that barks, barks does, does not, not bite\n",
    "3. trigrams (n=3): dog that barks, that barks does, barks does not, does not bite\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='dinosaur_ngrams.png'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3064, 169847)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# include 1-grams and 2-grams\n",
    "vect = CountVectorizer(ngram_range=(1, 2))\n",
    "X_train_dtm = vect.fit_transform(X_train)\n",
    "X_train_dtm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['zia', 'zia and', 'zihuatenejo', 'zihuatenejo awaited', 'zilch', 'zilch to', 'zin', 'zin that', 'zinburger', 'zinburger all', 'zinburger are', 'zinburger last', 'zinburger truffle', 'zinburger very', 'zinburger was', 'zinburgergeist', 'zinburgergeist and', 'zinc', 'zinc lozenge', 'zinc supplementation', 'zinfandel', 'zinfandel for', 'zinfandel have', 'zing', 'zing to', 'zip', 'zip code', 'zip up', 'zipcar', 'zipcar at', 'zipper', 'zipper at', 'zippers', 'zippers flipstick', 'zipps', 'zipps decided', 'zipps or', 'ziti', 'ziti and', 'ziti stayed', 'zoe', 'zoe and', 'zoe kitchen', 'zombi', 'zombi has', 'zombi up', 'zombies', 'zombies the', 'zone', 'zone of', 'zone out', 'zone when', 'zones', 'zones dolls', 'zoning', 'zoning issues', 'zoo', 'zoo and', 'zoo is', 'zoo not', 'zoo the', 'zoo ve', 'zoyo', 'zoyo for', 'zucca', 'zucca appetizer', 'zucchini', 'zucchini and', 'zucchini bread', 'zucchini broccoli', 'zucchini carrots', 'zucchini fries', 'zucchini pieces', 'zucchini strips', 'zucchini veal', 'zucchini very', 'zucchini with', 'zuchinni', 'zuchinni again', 'zuchinni the', 'zumba', 'zumba class', 'zumba or', 'zumba yogalates', 'zupa', 'zupa flavors', 'zuzu', 'zuzu in', 'zuzu is', 'zuzu the', 'zwiebel', 'zwiebel kräuter', 'zzed', 'zzed in', 'éclairs', 'éclairs napoleons', 'école', 'école lenôtre', 'ém', 'ém all']\n"
     ]
    }
   ],
   "source": [
    "# last 50 features\n",
    "print(vect.get_feature_names()[-100:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use default options for CountVectorizer\n",
    "vect = CountVectorizer()\n",
    "\n",
    "# create documen-term matrix with normalization on both training and test set\n",
    "X_train_dtm = vect.fit_transform(X_train)\n",
    "X_test_dtm = vect.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes\n",
    "Naive Bayes classifiers are a family of simple probabilistic classifiers based on applying Bayes' theorem with strong (naive) independence assumptions between the features.\n",
    "\n",
    "Naive Bayes has been studied extensively since the 1950s. It was introduced under a different name into the text retrieval community in the early 1960s and remains a popular (baseline) method for text categorization, the problem of judging documents as belonging to one category or the other (such as spam or legitimate, sports or politics, etc.) with word frequencies as the features. With appropriate pre-processing, it is competitive in this domain with more advanced methods including support vector machines.\n",
    "<img src='nb.PNG'>\n",
    "- Posterior probability - the statistical probability that a hypothesis is true calculated in the light of relevant observations.\n",
    "- Prior probability - A prior probability distribution, often simply called the prior, of an uncertain quantity is the probability distribution that would express one's beliefs about this quantity before some evidence is taken into account.\n",
    "\n",
    "<img src='NBexample.JPG'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9187866927592955\n"
     ]
    }
   ],
   "source": [
    "# use Naive Bayes to predict the star rating\n",
    "nb = MultinomialNB()\n",
    "nb.fit(X_train_dtm, y_train)\n",
    "y_pred_class = nb.predict(X_test_dtm)\n",
    "\n",
    "# calculate accuracy\n",
    "print(metrics.accuracy_score(y_test, y_pred_class))\n",
    "#print(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let us Train the model for entire model\n",
    "<img src='family-guy-gif-training.gif'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function that accepts a vectorizer and calculates the accuracy\n",
    "def tokenize_test(vect):\n",
    "    X_train_dtm = vect.fit_transform(X_train)\n",
    "    print('Features: ', X_train_dtm.shape[1])\n",
    "    X_test_dtm = vect.transform(X_test)\n",
    "    nb = MultinomialNB()\n",
    "    nb.fit(X_train_dtm, y_train)\n",
    "    y_pred_class = nb.predict(X_test_dtm)\n",
    "    print('Accuracy: ', metrics.accuracy_score(y_test, y_pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features:  169847\n",
      "Accuracy:  0.8542074363992173\n"
     ]
    }
   ],
   "source": [
    "# include 1-grams and 2-grams\n",
    "vect = CountVectorizer(ngram_range=(1, 2))\n",
    "tokenize_test(vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 2), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show vectorizer options\n",
    "vect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Natural language processing (nlp) is a research field that presents many challenges such as natural language understanding.\n",
    "### Text may contain stop words like ‘the’, ‘is’, ‘are’. Stop words can be filtered from the text to be processed. There is no universal list of stop words in nlp research, however the nltk module contains a list of stop words.\n",
    "\n",
    "<img src='bigwords.jpg'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features:  16528\n",
      "Accuracy:  0.9158512720156555\n"
     ]
    }
   ],
   "source": [
    "# remove English stop words\n",
    "vect = CountVectorizer(stop_words='english')\n",
    "tokenize_test(vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frozenset({'ie', 'toward', 'due', 'under', 'when', 'become', 'other', 'since', 'do', 'sixty', 'yet', 'hereby', 'its', 'eg', 'amount', 'has', 'ten', 'system', 'i', 'whereafter', 'anyhow', 'being', 'hence', 'move', 'please', 'thence', 'whatever', 'than', 'whereupon', 'whether', 'towards', 'will', 'may', 'thin', 'very', 'after', 'twenty', 'you', 'whereas', 'no', 'those', 'why', 'via', 'found', 'therein', 'across', 'him', 'can', 'is', 'etc', 'could', 'latterly', 'meanwhile', 'so', 'such', 'throughout', 'somehow', 'he', 'moreover', 'up', 'whose', 'ltd', 'also', 'anyway', 'former', 'only', 'eleven', 'about', 'made', 'top', 'until', 'or', 'myself', 'her', 'mill', 'nine', 'sometime', 'became', 'there', 'both', 'by', 'had', 'nor', 'these', 'our', 'them', 'detail', 'again', 'formerly', 'although', 'seeming', 'show', 'and', 'it', 'someone', 'third', 'fifty', 'thru', 'below', 'call', 'already', 'beside', 'front', 'but', 'upon', 'ourselves', 'whoever', 'some', 'for', 'through', 'becomes', 'whereby', 'few', 'whither', 'between', 'at', 'get', 'seem', 'others', 'what', 'go', 'now', 'my', 'might', 'during', 'side', 'where', 'off', 'con', 'name', 'which', 'sincere', 'yourself', 'cant', 'that', 'ever', 'five', 'part', 'because', 'several', 'among', 'indeed', 'if', 'less', 'alone', 'us', 'cry', 'seemed', 'afterwards', 'thick', 'a', 'in', 'we', 'eight', 'fifteen', 'once', 'against', 'whole', 'before', 'nobody', 'nevertheless', 'everyone', 'anything', 'further', 'everywhere', 'she', 'beyond', 'more', 'un', 'always', 'into', 'together', 'should', 'done', 'an', 'be', 'becoming', 'much', 'first', 'thus', 'amoungst', 'same', 'full', 'besides', 'thereafter', 'mostly', 'though', 'not', 'something', 'two', 'whence', 'most', 'four', 'forty', 'from', 'still', 'almost', 'they', 'find', 'wherever', 'hers', 'whom', 'with', 'fill', 'somewhere', 'here', 'out', 'latter', 'per', 'well', 'every', 'were', 'interest', 'keep', 'each', 'seems', 'beforehand', 'take', 'thereupon', 'wherein', 'while', 'bill', 'themselves', 'nowhere', 'never', 'namely', 'last', 'cannot', 'the', 'either', 'amongst', 'inc', 'co', 'de', 'perhaps', 'often', 'all', 'rather', 'serious', 'enough', 'am', 'without', 'sometimes', 'yourselves', 'onto', 'fire', 'as', 'neither', 'nothing', 'hasnt', 'me', 'have', 'over', 'describe', 'back', 're', 'everything', 'who', 'hundred', 'whenever', 'noone', 'thereby', 'three', 'one', 'been', 'another', 'itself', 'anyone', 'twelve', 'many', 'own', 'then', 'your', 'of', 'six', 'within', 'otherwise', 'herself', 'above', 'even', 'must', 'ours', 'behind', 'therefore', 'mine', 'couldnt', 'elsewhere', 'down', 'any', 'too', 'himself', 'anywhere', 'to', 'herein', 'this', 'his', 'least', 'except', 'would', 'yours', 'around', 'hereupon', 'give', 'how', 'was', 'empty', 'however', 'next', 'see', 'none', 'put', 'bottom', 'along', 'else', 'hereafter', 'are', 'on', 'their'})\n"
     ]
    }
   ],
   "source": [
    "# set of stop words\n",
    "print(vect.get_stop_words())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features:  100\n",
      "Accuracy:  0.8698630136986302\n"
     ]
    }
   ],
   "source": [
    "# remove English stop words and only keep 100 features\n",
    "vect = CountVectorizer(stop_words='english', max_features=100)\n",
    "tokenize_test(vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['amazing', 'area', 'atmosphere', 'awesome', 'bad', 'bar', 'best', 'better', 'big', 'came', 'cheese', 'chicken', 'clean', 'coffee', 'come', 'day', 'definitely', 'delicious', 'did', 'didn', 'dinner', 'don', 'eat', 'excellent', 'experience', 'favorite', 'feel', 'food', 'free', 'fresh', 'friendly', 'friends', 'going', 'good', 'got', 'great', 'happy', 'home', 'hot', 'hour', 'just', 'know', 'like', 'little', 'll', 'location', 'long', 'looking', 'lot', 'love', 'lunch', 'make', 'meal', 'menu', 'minutes', 'need', 'new', 'nice', 'night', 'order', 'ordered', 'people', 'perfect', 'phoenix', 'pizza', 'place', 'pretty', 'prices', 'really', 'recommend', 'restaurant', 'right', 'said', 'salad', 'sandwich', 'sauce', 'say', 'service', 'staff', 'store', 'sure', 'table', 'thing', 'things', 'think', 'time', 'times', 'took', 'town', 'tried', 'try', 've', 'wait', 'want', 'way', 'went', 'wine', 'work', 'worth', 'years']\n"
     ]
    }
   ],
   "source": [
    "# all 100 features\n",
    "print(vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let us test with 100,000 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features:  100000\n",
      "Accuracy:  0.8855185909980431\n"
     ]
    }
   ],
   "source": [
    "# include 1-grams and 2-grams, and limit the number of features\n",
    "vect = CountVectorizer(ngram_range=(1, 2), max_features=100000)\n",
    "tokenize_test(vect)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='df.jpg'>\n",
    "\n",
    "### Let us test with document frequency where term occurance is greater than 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features:  43957\n",
      "Accuracy:  0.9324853228962818\n"
     ]
    }
   ],
   "source": [
    "# include 1-grams and 2-grams, and only include terms that appear at least 2 times\n",
    "vect = CountVectorizer(ngram_range=(1, 2), min_df=2)\n",
    "tokenize_test(vect)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reset\n",
    "<img src='reset.jpg'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My wife took me here on my birthday for breakfast and it was excellent.  The weather was perfect which made sitting outside overlooking their grounds an absolute pleasure.  Our waitress was excellent and our food arrived quickly on the semi-busy Saturday morning.  It looked like the place fills up pretty quickly so the earlier you get here the better.\n",
      "\n",
      "Do yourself a favor and get their Bloody Mary.  It was phenomenal and simply the best I've ever had.  I'm pretty sure they only use ingredients from their garden and blend them fresh when you order it.  It was amazing.\n",
      "\n",
      "While EVERYTHING on the menu looks excellent, I had the white truffle scrambled eggs vegetable skillet and it was tasty and delicious.  It came with 2 pieces of their griddled bread with was amazing and it absolutely made the meal complete.  It was the best \"toast\" I've ever had.\n",
      "\n",
      "Anyway, I can't wait to go back!\n"
     ]
    }
   ],
   "source": [
    "# print the first review\n",
    "print(yelp_best_worst.text[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'TextBlob' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-e773a1de71d0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m#It provides a simple API for diving into common natural language processing (NLP) tasks such as part-of-speech tagging,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m#noun phrase extraction, sentiment analysis, classification, translation, and more\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mreview\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextBlob\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0myelp_best_worst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#Using TextBlob for Text processing\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'TextBlob' is not defined"
     ]
    }
   ],
   "source": [
    "# save it as a TextBlob object \n",
    "#TextBlob is a Python (2 and 3) library for processing textual data. \n",
    "#It provides a simple API for diving into common natural language processing (NLP) tasks such as part-of-speech tagging, \n",
    "#noun phrase extraction, sentiment analysis, classification, translation, and more\n",
    "review = TextBlob(yelp_best_worst.text[0]) #Using TextBlob for Text processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list the words\n",
    "review.words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list the sentences\n",
    "review.sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# some string methods are available\n",
    "review.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stemming and lemmatization\n",
    "\n",
    "For grammatical reasons, documents are going to use different forms of a word, such as organize, organizes, and organizing. Additionally, there are families of derivationally related words with similar meanings, such as democracy, democratic, and democratization. In many situations, it seems as if it would be useful for a search for one of these words to return documents that contain another word in the set.\n",
    "\n",
    "The goal of both stemming and lemmatization is to reduce inflectional forms and sometimes derivationally related forms of a word to a common base form. For instance:\n",
    "\n",
    "am, are, is $\\Rightarrow$ be \n",
    "\n",
    "car, cars, car's, cars' $\\Rightarrow$ car\n",
    "\n",
    "The result of this mapping of text will be something like:\n",
    "\n",
    "the boy's cars are different colors $\\Rightarrow$ \n",
    "the boy car be differ color\n",
    "\n",
    "However, the two words differ in their flavor. \n",
    "\n",
    "Stemming usually refers to a crude heuristic process that chops off the ends of words in the hope of achieving this goal correctly most of the time, and often includes the removal of derivational affixes. \n",
    "\n",
    "Lemmatization usually refers to doing things properly with the use of a vocabulary and morphological analysis of words, normally aiming to remove inflectional endings only and to return the base or dictionary form of a word, which is known as the lemma .\n",
    "\n",
    "<img src='stem.png'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# initialize stemmer\n",
    "stemmer = SnowballStemmer('english') #SnowballStemmer is one of the algorithm for performing stemming operation\n",
    "\n",
    "# stem each word\n",
    "print([stemmer.stem(word) for word in review.words])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img class = 'one' src='same1.jpg'> <img class = 'one' src='lemma.jpg'> \n",
    "POS - Part of speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "#adverb a word or phrase that modifies the meaning of an adjective, verb, or other adverb, expressing manner, place, \n",
    "#time, or degree (e.g. gently, here, now, very ). Some adverbs, for example sentence adverbs, \n",
    "#can also be used to modify whole sentences.\n",
    "print(lemmatizer.lemmatize(\"better\", pos=\"a\")) #better, farther\n",
    "\n",
    "#noun a word (other than a pronoun) used to identify any of a class of people, places, or things ( common noun ), or to \n",
    "#name a particular one of these ( proper noun )\n",
    "print(lemmatizer.lemmatize(\"cats\", pos=\"n\")) #cats, dogs\n",
    "\n",
    "#verb a word used to describe an action, state, or occurrence, and forming the main part of the predicate of a sentence, \n",
    "#such as hear, become, happen\n",
    "print(lemmatizer.lemmatize(\"had\",pos=\"v\")) #slept, ate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <img class = 'two' src='same2.jpg'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assume every word is a noun\n",
    "print([word.lemmatize() for word in review.words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assume every word is a verb\n",
    "print([word.lemmatize(pos='v') for word in review.words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function that accepts text and returns a list of lemmas\n",
    "def split_into_lemmas(text):\n",
    "    text = text.lower()\n",
    "    words = TextBlob(text).words \n",
    "    return [word.lemmatize() for word in words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use split_into_lemmas as the feature extraction function (WARNING: SLOW!)\n",
    "vect = CountVectorizer(analyzer=split_into_lemmas)\n",
    "tokenize_test(vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# last 50 features which is having least significance\n",
    "print(vect.get_feature_names()[-50:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-iDF\n",
    "<img src='tfidf.png'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example documents\n",
    "simple_train = ['call you tonight', 'Call me a cab', 'please call me... PLEASE!']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Term Frequency\n",
    "vect = CountVectorizer()\n",
    "tf = pd.DataFrame(vect.fit_transform(simple_train).toarray(), columns=vect.get_feature_names())\n",
    "tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Document Frequency\n",
    "vect = CountVectorizer(binary=True)\n",
    "df = vect.fit_transform(simple_train).toarray().sum(axis=0)\n",
    "pd.DataFrame(df.reshape(1, 6), columns=vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Term Frequency-Inverse Document Frequency (simple version)\n",
    "tf/df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TfidfVectorizer - Higher the value, more its significant\n",
    "vect = TfidfVectorizer()\n",
    "pd.DataFrame(vect.fit_transform(simple_train).toarray(), columns=vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a document-term matrix using TF-IDF\n",
    "vect = TfidfVectorizer(stop_words='english')\n",
    "dtm = vect.fit_transform(yelp.text)\n",
    "features = vect.get_feature_names()\n",
    "dtm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize():\n",
    "    \n",
    "    # choose a random review that is at least 300 characters\n",
    "    review_length = 0\n",
    "    while review_length < 300:\n",
    "        review_id = np.random.randint(0, len(yelp))\n",
    "        review_text = yelp.text[review_id]\n",
    "        review_length = len(review_text)\n",
    "    \n",
    "    # create a dictionary of words and their TF-IDF scores\n",
    "    word_scores = {}\n",
    "    for word in TextBlob(review_text).words:\n",
    "        word = word.lower()\n",
    "        if word in features:\n",
    "            word_scores[word] = dtm[review_id, features.index(word)]\n",
    "    \n",
    "    # print words with the top 5 TF-IDF scores\n",
    "    print('TOP SCORING WORDS:')\n",
    "    top_scores = sorted(word_scores.items(), key=lambda x: x[1], reverse=True)[:10]\n",
    "    for word, score in top_scores:\n",
    "        print(word)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "summarize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importance\n",
    "This can be used for document clustering. In this example, Cocktails, Oysters, Martinis, inexpensive have scored very high and it tends to signify the values and aspiration of the review crowd.\n",
    "\n",
    "Examples of usage - Twitter trends, Cricket advertisement analysis, Launching a new product based on existing brand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis\n",
    "\n",
    "<img src='senti.jpg'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# polarity ranges from -1 (most negative) to 1 (most positive)\n",
    "review.sentiment.polarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='wifi.jpg'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let us do for entire Yelp dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# understanding the apply method\n",
    "yelp['length'] = yelp.text.apply(len)\n",
    "yelp.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function that accepts text and returns the polarity\n",
    "def detect_sentiment(text):\n",
    "    return TextBlob(text).sentiment.polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new DataFrame column for sentiment (WARNING: SLOW!)\n",
    "yelp['sentiment'] = yelp.text.apply(detect_sentiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Box Plot\n",
    "<img src='box_plot.png'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# box plot of sentiment grouped by stars\n",
    "yelp.boxplot(column='sentiment', by='stars')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reviews with most positive sentiment\n",
    "yelp[yelp.sentiment == 1].text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reviews with most negative sentiment\n",
    "yelp[yelp.sentiment == -1].text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# widen the column display\n",
    "pd.set_option('max_colwidth', 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Marked 5 star but Sentiment analysis shows negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# negative sentiment in a 5-star review\n",
    "yelp[(yelp.stars == 5) & (yelp.sentiment < -0.3)].head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Marked 1 star but Sentiment analysis shows positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# positive sentiment in a 1-star review\n",
    "yelp[(yelp.stars == 1) & (yelp.sentiment > 0.5)].head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset the column display width\n",
    "pd.reset_option('max_colwidth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='bazzinga.jpg'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next Logistic regression\n",
    "\n",
    "Logistic regression can be seen as a special case of the generalized linear model and thus analogous to linear regression. Logistic regression measures the relationship between the categorical dependent variable and one or more independent variables by estimating probabilities using a logistic function, which is the cumulative logistic distribution. \n",
    "\n",
    "<img src='LogReg_1.png'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a DataFrame that only contains the 5-star and 1-star reviews\n",
    "yelp_best_worst = yelp[(yelp.stars==5) | (yelp.stars==1)]\n",
    "\n",
    "# define X and y\n",
    "feature_cols = ['text', 'sentiment', 'cool', 'useful', 'funny']\n",
    "X = yelp_best_worst[feature_cols]\n",
    "y = yelp_best_worst.stars\n",
    "\n",
    "# split into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use CountVectorizer with text column only\n",
    "vect = CountVectorizer()\n",
    "X_train_dtm = vect.fit_transform(X_train.text)\n",
    "X_test_dtm = vect.transform(X_test.text)\n",
    "print(X_train_dtm.shape)\n",
    "print(X_test_dtm.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shape of other four feature columns\n",
    "X_train.drop('text', axis=1).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='sparse.jpg'><img src='csr.svg'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# cast other feature columns to float and convert to a sparse matrix\n",
    "extra = sp.sparse.csr_matrix(X_train.drop('text', axis=1).astype(float)) #https://docs.scipy.org/doc/scipy-0.19.0/reference/generated/scipy.sparse.csr_matrix.html\n",
    "extra.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine sparse matrices\n",
    "X_train_dtm_extra = sp.sparse.hstack((X_train_dtm, extra)) #Stack arrays in sequence horizontally (column wise).\n",
    "X_train_dtm_extra.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# repeat for testing set\n",
    "extra = sp.sparse.csr_matrix(X_test.drop('text', axis=1).astype(float))\n",
    "X_test_dtm_extra = sp.sparse.hstack((X_test_dtm, extra))\n",
    "X_test_dtm_extra.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use logistic regression with text column only\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train_dtm, y_train)\n",
    "y_pred_class = logreg.predict(X_test_dtm)\n",
    "print(metrics.accuracy_score(y_test, y_pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# use logistic regression with all features\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train_dtm_extra, y_train)\n",
    "y_pred_class = logreg.predict(X_test_dtm_extra)\n",
    "print(metrics.accuracy_score(y_test, y_pred_class))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Reference:\n",
    "1. https://www.youtube.com/watch?v=RZYjsw6P4nI - CountVectorizer\n",
    "2. https://en.wikipedia.org/wiki/Sparse_matrix\n",
    "3. http://www.nltk.org/howto/stem.html\n",
    "4. http://textminingonline.com/dive-into-nltk-part-iv-stemming-and-lemmatization\n",
    "5. https://pythonspot.com/en/nltk-stop-words/\n",
    "6. http://scikit-learn.org/stable/modules/feature_extraction.html\n",
    "7. https://de.dariah.eu/tatom/working_with_text.html\n",
    "8. https://www.youtube.com/watch?v=FLZvOKSCkxY&list=PLQVvvaa0QuDf2JswnfiGkliBInZnIC4HL <- One of the best to learn online\n",
    "9. http://zone.ni.com/reference/en-XX/help/373601B-01/lvmasmt/solving_partial_diff_eq_using_finite_element/ - Sparse matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='keepcalm.png'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
